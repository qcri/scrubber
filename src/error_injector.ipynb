{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import v6.data_io\n",
    "\n",
    "import utils.myconfig\n",
    "\n",
    "from deep_blocker import DeepBlocker \n",
    "from tuple_embedding_models import  AutoEncoderTupleEmbedding, CTTTupleEmbedding, HybridTupleEmbedding\n",
    "from vector_pairing_models import ExactTopKVectorPairing\n",
    "import blocking_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "tuple_embedding_model = AutoEncoderTupleEmbedding()\n",
    "vector_pairing_model = ExactTopKVectorPairing(K=50)\n",
    "blocker = DeepBlocker(tuple_embedding_model, vector_pairing_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocking_candidates(tab_A, tab_B, pair2index):\n",
    "    # find common attributes for blocking\n",
    "    cols_to_block = tab_A.columns & tab_B.columns\n",
    "    print('Common attributes used for blocking: ', cols_to_block[:2])\n",
    "    candidate_set_df = blocker.block_datasets(tab_A, tab_B, cols_to_block[:2])\n",
    "    print('Candidates set: ', candidate_set_df)\n",
    "    \n",
    "    # lookup candidates in given indexes\n",
    "    candidates = []\n",
    "    for i, row in candidate_set_df.iterrows():\n",
    "        pair = (row['ltable_id'], row['rtable_id'])\n",
    "        if pair in pair2index:\n",
    "            candidates.append(pair)\n",
    "            print('Found candidate pair: ', pair)\n",
    "\n",
    "    print('Number of candidates found: ', len(candidates))\n",
    "    return candidates\n",
    "\n",
    "def read_table(basedir, tab_name):\n",
    "    return pd.read_csv(os.path.join(basedir, tab_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was: 0\n",
      "Error rate: 0.2\n",
      "Common attributes used for blocking:  Index(['id', 'bike_name'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15785/826932214.py:3: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  cols_to_block = tab_A.columns & tab_B.columns\n",
      "/home/local/QCRI/mkunjir/anaconda3/envs/debugger/lib/python3.9/site-packages/pandas/core/frame.py:5176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing pre-processing for tuple embeddings \n",
      "Training AutoEncoder model\n",
      "Obtaining tuple embeddings for left table\n",
      "Obtaining tuple embeddings for right table\n",
      "Indexing the embeddings from the right dataset\n",
      "Querying the embeddings from left dataset\n",
      "Candidates set:          ltable_id  rtable_id\n",
      "0               0       8274\n",
      "1               1       4113\n",
      "2               2       7061\n",
      "3               3       7354\n",
      "4               4       5835\n",
      "...           ...        ...\n",
      "239295       4781       7132\n",
      "239296       4782       2473\n",
      "239297       4783       3936\n",
      "239298       4784       5401\n",
      "239299       4785       7018\n",
      "\n",
      "[239300 rows x 2 columns]\n",
      "Number of candidates found:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (0, 0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15785/3581770343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0minject_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15785/3581770343.py\u001b[0m in \u001b[0;36minject_errors\u001b[0;34m(errors)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_error_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_err\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meligible_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meligible_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# candidate pair index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/debugger/lib/python3.9/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/debugger/lib/python3.9/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d, %d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (0, 0, 0)"
     ]
    }
   ],
   "source": [
    "def inject_errors(errors=0.2):\n",
    "    config_file=r'/export/da/mkunjir/LabelDebugger/config/bike.config'\n",
    "\n",
    "    params = utils.myconfig.read_config(config_file)\n",
    "\n",
    "    basedir = params['basedir']\n",
    "    hpath = os.path.join(basedir, params['hpath'])\n",
    "    gpath = os.path.join(basedir, 'golden.csv')\n",
    "\n",
    "    exclude_attrs = ['_id', 'ltable.id', 'rtable.id']\n",
    "\n",
    "    features, labels, pair2index, index2pair = v6.data_io.read_feature_file(hpath, exclude_attrs)\n",
    "    pair2golden = v6.data_io.read_golden_label_file(gpath)\n",
    "\n",
    "    #print('pair2index: ', pair2index)\n",
    "    # label errors\n",
    "    all_errors = []\n",
    "    for index, p in index2pair.items():\n",
    "        if labels[index]!=pair2golden[p]:\n",
    "            #print('Error found at: ', index, ' the pair is: ', p)\n",
    "            all_errors.append(index)\n",
    "\n",
    "    # randomly insert errors\n",
    "    seed = 0 \n",
    "    rng = random.Random(seed)\n",
    "    print(\"Seed was:\", seed)\n",
    "\n",
    "    perc = errors #rng.randint(5, 15)/100.0\n",
    "    print(\"Error rate:\", perc)\n",
    "\n",
    "    num_err = int(len(labels)*perc)\n",
    "    if num_err < len(all_errors):\n",
    "        print(\"Existing errors larger than the error rate specified!\")\n",
    "        exit()\n",
    "    \n",
    "    # get candidates by blocking\n",
    "    table_A = read_table(basedir, params['apath'])\n",
    "    table_B = read_table(basedir, params['bpath'])\n",
    "    eligible_indices = blocking_candidates(table_A, table_B, pair2index)\n",
    "    \n",
    "    error_indices = set(all_errors)\n",
    "    new_error_indices = set()\n",
    "    for _ in range(num_err*10):\n",
    "        if len(new_error_indices) >= num_err-len(error_indices):\n",
    "            break\n",
    "        num = rng.randint(0, len(eligible_indices)-1)\n",
    "        index = eligible_indices[num] # candidate pair index\n",
    "        if index in error_indices:\n",
    "            continue\n",
    "        new_error_indices.add(index)\n",
    "        labels[index] = 0 if labels[index]==1 else 1\n",
    "        \n",
    "    # write new labels along with features\n",
    "    fv_df = pd.read_csv(hpath)\n",
    "    new_hpath = os.path.join(basedir, 'feature_vector_errors-' + str(errors) + '.csv')\n",
    "    print('New errors inserted: ', len(new_error_indices))\n",
    "    for cnt, index in enumerate(new_error_indices):\n",
    "      pair = index2pair[index]\n",
    "      fv_df.at[index, 'label'] = labels[index]\n",
    "    fv_df.to_csv(new_hpath, index=False)\n",
    "\n",
    "    print(\"Total number of errors: \", len(error_indices) + len(new_error_indices))\n",
    "    all_errors = list(error_indices)\n",
    "    all_errors.extend(list(new_error_indices))\n",
    "\n",
    "\n",
    "inject_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
