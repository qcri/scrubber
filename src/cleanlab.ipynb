{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplified Confident Learning Tutorial\n",
    "Author: Curtis G. Northcutt, cgn@mit.edu\n",
    "\n",
    "In this tutorial, we show how to implement confident learning without using cleanlab (for the most part). This tutorial is to confident learning what this tutorial https://pytorch.org/tutorials/beginner/examples_tensor/two_layer_net_numpy.html is to deep learning.\n",
    "\n",
    "The actual implementations in cleanlab are complex because they support parallel processing, numerous type and input checks, lots of hyper-parameter settings, lots of utilities to make things work smoothly for all types of inputs, and ancillary functions.\n",
    "\n",
    "I ignore all of that here and provide you a bare-bones implementation using mostly for-loops and some numpy. Here we'll do two simple things:\n",
    "\n",
    "Compute the confident joint which fully characterizes all label noise.\n",
    "Find the indices of all label errors, ordered by likelihood of being an error.\n",
    "INPUT (stuff we need beforehand):\n",
    "s - These are the noisy labels. This is an np.array of noisy labels, shape (n,1)\n",
    "psx - These are the out-of-sample holdout predicted probabilities for every example in your dataset. This is an np.array (2d) of probabilities, shape (n, m)\n",
    "OUTPUT (what this returns):\n",
    "confident_joint - an (m, m) np.array matrix characterizing all the label error counts for every pair of labels.\n",
    "label_errors_idx - a numpy array comprised of indices of every label error, ordered by likelihood of being a label error.\n",
    "In this tutorial we use the handwritten digits dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division, with_statement\n",
    "import cleanlab\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# To silence convergence warnings caused by using a weak\n",
    "# logistic regression classifier on image data\n",
    "import warnings\n",
    "\n",
    "## mayuresh: label debugger code\n",
    "import os\n",
    "from utils import myconfig\n",
    "from v6 import data_io, feature_selection, detector, label_debugger\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mayuresh:\n",
    "# Get data from LabelDebugger config files\n",
    "\n",
    "def read_config(config_file):\n",
    "    params = myconfig.read_config(config_file)\n",
    "    return params\n",
    "\n",
    "def read_dataset(params):\n",
    "    basedir = params['basedir']\n",
    "    hpath = os.path.join(basedir, params['hpath'])\n",
    "    exclude_attrs = ['_id', 'ltable.id', 'rtable.id']\n",
    "    params['fs_alg'] = 'model'\n",
    "    features, labels, pair2index, index2pair = data_io.read_feature_file(hpath, exclude_attrs)\n",
    "    selected_features = feature_selection.select_features(features, labels, params['fs_alg'])\n",
    "    return selected_features, labels\n",
    "\n",
    "def compare_golden(params):\n",
    "    basedir = params['basedir']\n",
    "    hpath = os.path.join(basedir, params['hpath'])\n",
    "    exclude_attrs = ['_id', 'ltable.id', 'rtable.id']\n",
    "    features, labels, pair2index, index2pair = data_io.read_feature_file(hpath, exclude_attrs)\n",
    "    gpath = os.path.join(basedir, 'golden.csv')\n",
    "    pair2golden = data_io.read_golden_label_file(gpath)\n",
    "\n",
    "    # label errors\n",
    "    all_errors = []\n",
    "    true_labels = []\n",
    "    for index, p in index2pair.items():\n",
    "        true_labels.append(pair2golden[p])\n",
    "        if labels[index]!=pair2golden[p]:\n",
    "            all_errors.append(index)\n",
    "    return true_labels, all_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM dataset number of classes: 2\n",
      "EM dataset number of examples: 71466\n",
      "EM dataset features shape: (71466, 9)\n",
      "\n",
      "Number of errors in dataset:  3827\n",
      "\n",
      "Indices of actual label errors:\n",
      " [   13    16    25 ... 71414 71446 71459]\n"
     ]
    }
   ],
   "source": [
    "# STEP 0 - Get some real digits data. Add a bunch of label errors. Get probs.\n",
    "\n",
    "# Get handwritten digits data\n",
    "#X = load_digits()['data']\n",
    "#y = load_digits()['target']\n",
    "#print('Handwritten digits datasets number of classes:', len(np.unique(y)))\n",
    "#print('Handwritten digits datasets number of examples:', len(y))\n",
    "\n",
    "## mayuresh: Get EM dataset, inject errors\n",
    "params = read_config('/export/da/mkunjir/LabelDebugger/config/cora.config')\n",
    "X, y = read_dataset(params)\n",
    "print('EM dataset number of classes:', len(np.unique(y)))\n",
    "print('EM dataset number of examples:', len(y))\n",
    "print('EM dataset features shape:', X.shape)\n",
    "\n",
    "\n",
    "# Add lots of errors to labels\n",
    "#NUM_ERRORS = 44\n",
    "s = np.array(y)\n",
    "#error_indices = np.random.choice(len(s), NUM_ERRORS, replace=False)\n",
    "#for i in error_indices:\n",
    "    # Switch to some wrong label thats a different class\n",
    "#    wrong_label = 1 - s[i] ## mayuresh: for binary case #np.random.choice(np.delete(range(np.unique(y)), s[i]))\n",
    "#    s[i] = wrong_label\n",
    "\n",
    "## mayuresh: read errors by comparing with golden labels\n",
    "y, error_indices = compare_golden(params)\n",
    "NUM_ERRORS = len(error_indices)\n",
    "print('\\nNumber of errors in dataset: ', NUM_ERRORS)\n",
    "\n",
    "# Confirm that we indeed added NUM_ERRORS label errors\n",
    "assert (len(s) - sum(s == y) == NUM_ERRORS)\n",
    "actual_label_errors = np.arange(len(y))[s != y]\n",
    "print('\\nIndices of actual label errors:\\n', actual_label_errors)\n",
    "\n",
    "# To keep the tutorial short, we use cleanlab to get the \n",
    "# out-of-sample predicted probabilities using cross-validation\n",
    "# with a very simple, non-optimized logistic regression classifier\n",
    "psx = cleanlab.latent_estimation.estimate_cv_predicted_probabilities(\n",
    "    X, s, clf=LogisticRegression(max_iter=1000, multi_class='auto', solver='lbfgs'), \n",
    "    cv_n_folds=5)\n",
    "\n",
    "# Now we have our noisy labels s and predicted probabilities psx.\n",
    "# That's all we need for confident learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class thresholds after averaging:  [0.96188014 0.96187577]\n",
      "\n",
      " Joint Label Noise Distribution Matrix P(s,y) of shape (2, 2)\n",
      " p(s,y)\ty=0\ty=1\n",
      "\t---\t---\n",
      "s=0 |\t35661\t72\n",
      "s=1 |\t196\t35537\n",
      "\tTrace(matrix) = 71198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 - Compute confident joint\n",
    "\n",
    "# Verify inputs\n",
    "s = np.asarray(s)\n",
    "psx = np.asarray(psx)\n",
    "\n",
    "# Find the number of unique classes if K is not given\n",
    "K = len(np.unique(s))\n",
    "\n",
    "# Estimate the probability thresholds for confident counting\n",
    "# You can specify these thresholds yourself if you want\n",
    "# as you may want to optimize them using a validation set.\n",
    "# By default (and provably so) they are set to the average class prob.\n",
    "thresholds = [np.mean(psx[:,k][s == k]) for k in range(K)] # P(s^=k|s=k)\n",
    "thresholds = np.asarray(thresholds)\n",
    "print('\\nClass thresholds after averaging: ', thresholds)\n",
    "#thresholds = np.array([.5, .5])\n",
    "\n",
    "# Compute confident joint\n",
    "confident_joint = np.zeros((K, K), dtype = int)\n",
    "for i, row in enumerate(psx):\n",
    "    s_label = s[i]\n",
    "    # Find out how many classes each example is confidently labeled as\n",
    "    confident_bins = row >= thresholds - 1e-6\n",
    "    num_confident_bins = sum(confident_bins)\n",
    "    # If more than one conf class, inc the count of the max prob class\n",
    "    if num_confident_bins == 1:\n",
    "        confident_joint[s_label][np.argmax(confident_bins)] += 1\n",
    "    elif num_confident_bins > 1:\n",
    "        confident_joint[s_label][np.argmax(row)] += 1\n",
    "\n",
    "# Normalize confident joint (use cleanlab, trust me on this)\n",
    "confident_joint = cleanlab.latent_estimation.calibrate_confident_joint(\n",
    "    confident_joint, s)\n",
    "\n",
    "cleanlab.util.print_joint_matrix(confident_joint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of label errors found by confident learning:\n",
      "Note label errors are sorted by likelihood of being an error\n",
      "but here we just sort them by index for comparison with above.\n",
      "[53200 36922 63986 38429 68068 20153  2374 30408 17564  2655 39086 68506\n",
      " 14901 47232 64109 38191 57856 37278  9048 43733 39255 54175 53127 70293\n",
      " 11475 48341 63844 39562 43644  9355 28183 25838 45506 33152 44407 21712\n",
      " 28999 42112 58968 51396 11469 31730 42415 43038 62701 42050 24762 50567\n",
      " 60672 23687 56624 39216  3207 12882 24728 61521 28283 32726 12366 19383\n",
      " 12242 60278 23382  3807 39589  8863 45192  2963 25566 45001 67894 69816\n",
      " 33687 29798 31768 12605 20399 44271 25202  2310 68440 19650 38421 38502\n",
      " 44997  5926 23841 12082 38499 14556 53138 12325 27825 48988 30386 59535\n",
      " 50968 28959 27684   600 10318  7381 58764 46017  5417  2808  4657 45280\n",
      " 27452 48296 15705 39929 60381 48770 29989 14571 15993 69616 49752 25658\n",
      " 55979 35013 20455 61794 11826 43789 15529 54956 47554 15464 62367 42370\n",
      " 20209 65695 41994 67869 68086 65096 30279 24602 23224 59532 19945 69255\n",
      " 71165 62231 55588 59735 20243 42018 30254 23191 45077  4939 40025 24358\n",
      " 62405  2400 44738  9214 62714 34922 40312 31547 47752 70823 67311 12134\n",
      " 43779  5625 60121 59201 56992 13164 56161 66102 67572 11595 35956 69052\n",
      " 37265 16044 53114 51199  8168   967 57312 18468 41253 61278 14541 28581\n",
      " 23944 27222 56035 34502 38213 16298 47655 56637 51497 23188 48782 58801\n",
      " 42441 31461 29597 52913 49060 61853 45156 37953 43034 69317 58406 16922\n",
      " 65522 48292 46825 16328 44147 14917 37323 38618 51052 32923 25921 46302\n",
      " 35568 29883 39793 60837 22316 64197 37107 18612 68991 12575 52141 45089\n",
      " 24094 21684 53149 63113 46044 17847 36630 60921 17249 49275 47643 51316\n",
      " 22811 29770 31052 60041 69422  1134  7574  5100  1178   428 41182 29088\n",
      " 26774 27235  5145 35046]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 - Find label errors\n",
    "\n",
    "# We arbitrarily choose at least 5 examples left in every class.\n",
    "# Regardless of whether some of them might be label errors.\n",
    "MIN_NUM_PER_CLASS = 5\n",
    "# Leave at least MIN_NUM_PER_CLASS examples per class.\n",
    "# NOTE prune_count_matrix is transposed (relative to confident_joint)\n",
    "prune_count_matrix = cleanlab.pruning.keep_at_least_n_per_class(\n",
    "    prune_count_matrix=confident_joint.T,\n",
    "    n=MIN_NUM_PER_CLASS,\n",
    ")\n",
    "\n",
    "s_counts = np.bincount(s)\n",
    "noise_masks_per_class = []\n",
    "# For each row in the transposed confident joint\n",
    "for k in range(K):\n",
    "    noise_mask = np.zeros(len(psx), dtype=bool)\n",
    "    psx_k = psx[:, k]\n",
    "    if s_counts[k] > MIN_NUM_PER_CLASS:  # Don't prune if not MIN_NUM_PER_CLASS\n",
    "        for j in range(K):  # noisy label index (k is the true label index)\n",
    "            if k != j:  # Only prune for noise rates, not diagonal entries\n",
    "                num2prune = prune_count_matrix[k][j]\n",
    "                if num2prune > 0:\n",
    "                    # num2prune'th largest p(classk) - p(class j)\n",
    "                    # for x with noisy label j\n",
    "                    margin = psx_k - psx[:, j]\n",
    "                    s_filter = s == j\n",
    "                    threshold = -np.partition(\n",
    "                        -margin[s_filter], num2prune - 1\n",
    "                    )[num2prune - 1]\n",
    "                    noise_mask = noise_mask | (s_filter & (margin >= threshold))\n",
    "        noise_masks_per_class.append(noise_mask)\n",
    "    else:\n",
    "        noise_masks_per_class.append(np.zeros(len(s), dtype=bool))\n",
    "\n",
    "# Boolean label error mask\n",
    "label_errors_bool = np.stack(noise_masks_per_class).any(axis=0)\n",
    "\n",
    " # Remove label errors if given label == model prediction\n",
    "for i, pred_label in enumerate(psx.argmax(axis=1)):\n",
    "    # np.all let's this work for multi_label and single label\n",
    "    if label_errors_bool[i] and np.all(pred_label == s[i]):\n",
    "        label_errors_bool[i] = False\n",
    "\n",
    "# Convert boolean mask to an ordered list of indices for label errors\n",
    "label_errors_idx = np.arange(len(s))[label_errors_bool]\n",
    "# self confidence is the holdout probability that an example\n",
    "# belongs to its given class label\n",
    "self_confidence = np.array(\n",
    "    [np.mean(psx[i][s[i]]) for i in label_errors_idx]\n",
    ")\n",
    "margin = self_confidence - psx[label_errors_bool].max(axis=1)\n",
    "label_errors_idx = label_errors_idx[np.argsort(margin)]\n",
    "\n",
    "print('Indices of label errors found by confident learning:')\n",
    "print('Note label errors are sorted by likelihood of being an error')\n",
    "print('but here we just sort them by index for comparison with above.')\n",
    "print(label_errors_idx) #(np.array(sorted(label_errors_idx)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% actual errors that confident learning found: 58\n",
      "% confident learning errors that are actual errors: 22%\n"
     ]
    }
   ],
   "source": [
    "score = sum([e in label_errors_idx for e in actual_label_errors])\n",
    "print('% actual errors that confident learning found: {}'.format(score))\n",
    "score = sum([e in actual_label_errors for e in label_errors_idx]) / len(label_errors_idx)\n",
    "print('% confident learning errors that are actual errors: {:.0%}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
