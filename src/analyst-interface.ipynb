{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import myconfig\n",
    "import v6.data_io, v6.feature_selection, v6.label_debugger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## debug iterations\n",
    "def debug_labels(debugger, index2pair, table_A, table_B, top_k, max_iter, file_prefix):\n",
    "\n",
    "    iter_times = []\n",
    "    correct_label_attr = 'correct_label'\n",
    "    num_iter_without_errors = 0\n",
    "    all_detected_errors = []\n",
    "    match_detected_errors = []\n",
    "    total_num_iters = 0\n",
    "    start = time.clock()\n",
    "\n",
    "    while True:\n",
    "        top_suspicious_indices = debugger.find_suspicious_labels(top_k)\n",
    "\n",
    "        end = time.clock()\n",
    "        iter_time = end-start\n",
    "        iter_times.append(iter_time)\n",
    "\n",
    "        # combine those suspicious pairs into a dataframe and save to file\n",
    "        all_pairs_with_label = []\n",
    "\n",
    "        # find their correct labels from analyst\n",
    "        index2correct_label = {}\n",
    "        for index in top_suspicious_indices:\n",
    "            p = index2pair[index]\n",
    "            label = labels[index]\n",
    "            try:\n",
    "                left = table_A.loc[table_A['id'] == int(p[0])]\n",
    "                right = table_B.loc[table_B['id'] == int(p[1])]\n",
    "            except: # possible casting to int is the culprit\n",
    "                left = table_A.loc[table_A['id'] == p[0]]\n",
    "                right = table_B.loc[table_B['id'] == p[1]]\n",
    "\n",
    "            tmp = {}\n",
    "            for col in left:\n",
    "                tmp['ltable.'+col] = left.iloc[0][col]\n",
    "            for col in right:\n",
    "                tmp['rtable.'+col] = right.iloc[0][col]\n",
    "            #tmp['label'] = label\n",
    "            all_pairs_with_label.append(tmp)\n",
    "\n",
    "        ## ask analyst if the labels are correct, add to index2correct_label\n",
    "        df = pd.DataFrame(all_pairs_with_label)\n",
    "        display_df = df[[c for c in df.columns if not any(map(c.startswith, ['ltable.id', 'rtable.id', 'ltable.assembled', 'rtable.assembled']))\n",
    "                         and not df[c].isnull().values.all()]]\n",
    "        display(HTML(display_df.to_html(index=False)))\n",
    "        #choice = '00000000000000000000'\n",
    "        choice = raw_input(\"Inspect the table and enter 0/1 to signify non-match/match. The input length should be: \" + str(len(top_suspicious_indices)) + '\\n')\n",
    "        ## TODO: verify inputs\n",
    "        original_labels = [labels[i] for i in top_suspicious_indices]\n",
    "        correct_labels = [int(c) for c in choice]\n",
    "        assert len(correct_labels) == len(top_suspicious_indices)\n",
    "\n",
    "        df['label'] = original_labels\n",
    "        df[correct_label_attr] = correct_labels\n",
    "\n",
    "        output_file = file_prefix + '_iter_' + str(debugger.iter_count) + '.csv'\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        corrected_labels_map = {i:c for (i, c) in zip(top_suspicious_indices, correct_labels)}\n",
    "        iter_count, num_errors, error_indices, match_error_indices, det_error_poses  = debugger.analyze(corrected_labels_map)\n",
    "        print('Iteration: ', iter_count)\n",
    "        print('Number of suspicious labels found: ', len(top_suspicious_indices))\n",
    "        print(\"Number of errors found: \", num_errors)\n",
    "        print(\"Error indices in the table: \", [top_suspicious_indices.index(i) for i in error_indices])\n",
    "        print(\"Detector performance: \")\n",
    "        for n, (count, pos) in enumerate(det_error_poses):\n",
    "            print(\"Detector \", n, \"found \", count, \" errors\")\n",
    "            #print(\"Positions: \", pos)\n",
    "\n",
    "        all_detected_errors.extend(error_indices)\n",
    "        match_detected_errors.extend(match_error_indices)\n",
    "\n",
    "        if num_errors==0:\n",
    "            num_iter_without_errors += 1\n",
    "        else:\n",
    "            num_iter_without_errors = 0\n",
    "\n",
    "        if num_iter_without_errors>=3:\n",
    "            break\n",
    "\n",
    "        start = time.clock()\n",
    "        index2correct_label = {index: correct_labels[i] for i, index in enumerate(top_suspicious_indices)}\n",
    "        debugger.correct_labels(index2correct_label)\n",
    "        ## mayuresh: explanations\n",
    "        print('---Explanations for wrong matches and wrong non-matches follow---')\n",
    "        debugger.explain_errors(False)\n",
    "        debugger.explain_errors(True)\n",
    "\n",
    "        total_num_iters += 1\n",
    "\n",
    "        if total_num_iters>=max_iter:\n",
    "            break\n",
    "\n",
    "    return all_detected_errors, match_detected_errors, iter_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from LabelDebugger config files\n",
    "\n",
    "def read_config(config_file):\n",
    "    params = myconfig.read_config(config_file)\n",
    "    # other config params\n",
    "    params['fs_alg'] = 'model'\n",
    "    params['max_list_len'] = 20\n",
    "    params['detectors'] = 'fpfn'\n",
    "    params['confusion'] = True\n",
    "    params['num_cores'] = 1\n",
    "    params['num_folds'] = 5\n",
    "    params['min_con_dim'] = 1\n",
    "    params['counting_only'] = True\n",
    "    params['top_k'] = 20\n",
    "    params['max_iter'] = 10\n",
    "\n",
    "    return params\n",
    "\n",
    "def read_table(basedir, tab_name):\n",
    "    return pd.read_csv(os.path.join(basedir, tab_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify username; the output path will use the name\n",
    "username = 'fake'\n",
    "\n",
    "# Specify the configuration file path of your dataset\n",
    "config_path = '/export/da/mkunjir/LabelDebugger/config/tools.config'\n",
    "params = read_config(config_path)\n",
    "\n",
    "# Optional: Change the budget parameters by uncommenting and setting desired values\n",
    "#params['top_k'] = 10 # The number of examples inspected in each iterations\n",
    "params['max_iter'] = 10 # The maximum number of debugging iterations\n",
    "\n",
    "# read features and labels\n",
    "basedir = params['basedir']\n",
    "hpath = os.path.join(basedir, params['hpath'])\n",
    "exclude_attrs = ['_id', 'ltable.id', 'rtable.id']\n",
    "features, labels, feature_labels, pair2index, index2pair = v6.data_io.read_feature_file(hpath, exclude_attrs)\n",
    "\n",
    "# read tables\n",
    "table_A = read_table(basedir, params['apath'])\n",
    "table_B = read_table(basedir, params['bpath'])\n",
    "\n",
    "# select features\n",
    "del params['spath']\n",
    "if 'spath' in params:\n",
    "       selected_features_path = os.path.join(basedir, params['spath'])\n",
    "       selected_features = pd.read_csv(selected_features_path).to_numpy()\n",
    "else:\n",
    "       selected_features, selected_feature_indexes = v6.feature_selection.select_features(features, labels, params['fs_alg'])\n",
    "       print('Selected features: ', [feature_labels[i] for i in selected_feature_indexes])\n",
    "       #selected_features = v6.feature_selection.select_features(selected_features, labels, params['fs_alg'])\n",
    "       selected_features_path = os.path.join(basedir, 'selected_features.csv')\n",
    "       pd.DataFrame(selected_features).to_csv(selected_features_path, index=False)\n",
    "print('Selected features of dim: ', selected_features.shape, ' from the original features: ', features.shape)\n",
    "params['fs_alg'] = 'none' # disabling feature selection now that we are done selecting \n",
    "\n",
    "# set debugger\n",
    "debugger = v6.label_debugger.LabelDebugger(selected_features, labels, params)\n",
    "\n",
    "# start debugging\n",
    "all_detected_errors, match_detected_errors, iter_times = debug_labels(debugger, index2pair, table_A, table_B, params['top_k'], params['max_iter'],\n",
    "                                                                      '/export/da/mkunjir/LabelDebugger/analyst/' + username + '_' + params['dataset_name'])\n",
    "print '\\n\\n'\n",
    "print(\"Number of iterations: \", debugger.iter_count)\n",
    "print(\"Number of checked pairs: \", len(debugger.verified_indices))\n",
    "print(\"Number of detected errors: \", len(all_detected_errors))\n",
    "print(\"Of which false non-matches: \", len(match_detected_errors))\n",
    "print(\"First iteration (secs): \", iter_times[0])\n",
    "print(\"For other iterations: \")\n",
    "print(\"Min (secs): \", min(iter_times[1:]))\n",
    "print(\"Max (secs): \", max(iter_times[1:]))\n",
    "print(\"Ave (secs): \", sum(iter_times[1:])/len(iter_times[1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
